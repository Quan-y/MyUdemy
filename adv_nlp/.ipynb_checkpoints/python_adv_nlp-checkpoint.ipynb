{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "mystopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fishing</th>\n",
       "      <th>hiking</th>\n",
       "      <th>machinelearning</th>\n",
       "      <th>mathematics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,4570,7-153-10364-34956--,00.html_12180052900...</td>\n",
       "      <td>351.html_122506814000.txt</td>\n",
       "      <td>10-algorithms-machine-learning-engineers.html_...</td>\n",
       "      <td>3_123525687000.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2347.htm_121805687000.txt</td>\n",
       "      <td>7bc1a822-6595-11e7-8eb5-cbccc2e7bfbf_story.htm...</td>\n",
       "      <td>10215-get-a-job-in-artificial-intelligence.htm...</td>\n",
       "      <td>8949890_123342435000.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ways.html_121816046000.txt</td>\n",
       "      <td>alander_mountain_122422037000.txt</td>\n",
       "      <td>10994_122716488000.txt</td>\n",
       "      <td>annals.math.princeton.edu_123544995000.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46-bait-and-tackle-palisades-park_121721321000...</td>\n",
       "      <td>americanhiking.org_122445384000.txt</td>\n",
       "      <td>1838_122730095000.txt</td>\n",
       "      <td>article_439742b4-9b2c-11e7-9aef-179971133ef1.h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-rescued-from-capsized-sport-fishing-boat-at-...</td>\n",
       "      <td>best-hikes-san-juan-islands_122601624000.txt</td>\n",
       "      <td>2017-09-quantum-machines.html_122800945000.txt</td>\n",
       "      <td>imapp_123402680000.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             fishing  \\\n",
       "0  0,4570,7-153-10364-34956--,00.html_12180052900...   \n",
       "1                          2347.htm_121805687000.txt   \n",
       "2                        3ways.html_121816046000.txt   \n",
       "3  46-bait-and-tackle-palisades-park_121721321000...   \n",
       "4  5-rescued-from-capsized-sport-fishing-boat-at-...   \n",
       "\n",
       "                                              hiking  \\\n",
       "0                          351.html_122506814000.txt   \n",
       "1  7bc1a822-6595-11e7-8eb5-cbccc2e7bfbf_story.htm...   \n",
       "2                  alander_mountain_122422037000.txt   \n",
       "3                americanhiking.org_122445384000.txt   \n",
       "4       best-hikes-san-juan-islands_122601624000.txt   \n",
       "\n",
       "                                     machinelearning  \\\n",
       "0  10-algorithms-machine-learning-engineers.html_...   \n",
       "1  10215-get-a-job-in-artificial-intelligence.htm...   \n",
       "2                             10994_122716488000.txt   \n",
       "3                              1838_122730095000.txt   \n",
       "4     2017-09-quantum-machines.html_122800945000.txt   \n",
       "\n",
       "                                         mathematics  \n",
       "0                                 3_123525687000.txt  \n",
       "1                           8949890_123342435000.txt  \n",
       "2         annals.math.princeton.edu_123544995000.txt  \n",
       "3  article_439742b4-9b2c-11e7-9aef-179971133ef1.h...  \n",
       "4                             imapp_123402680000.txt  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataFrame filename\n",
    "filename = pd.DataFrame([os.listdir('workshop_data/{0}'.format(i)) for i in os.listdir('workshop_data')]).T\n",
    "filename.columns = os.listdir('workshop_data')\n",
    "filename.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,4570,7-153-10364-34956--,00.html_12180052900...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2347.htm_121805687000.txt</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ways.html_121816046000.txt</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46-bait-and-tackle-palisades-park_121721321000...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-rescued-from-capsized-sport-fishing-boat-at-...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    label\n",
       "0  0,4570,7-153-10364-34956--,00.html_12180052900...  fishing\n",
       "1                          2347.htm_121805687000.txt  fishing\n",
       "2                        3ways.html_121816046000.txt  fishing\n",
       "3  46-bait-and-tackle-palisades-park_121721321000...  fishing\n",
       "4  5-rescued-from-capsized-sport-fishing-boat-at-...  fishing"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another data type\n",
    "new_filename = []\n",
    "filename = [os.listdir('workshop_data/{0}'.format(i)) for i in os.listdir('workshop_data')]\n",
    "for i in filename:\n",
    "    new_filename.extend(i)\n",
    "label = []\n",
    "for i, j in zip(filename, os.listdir('workshop_data')):\n",
    "    label.extend([j]*len(i))\n",
    "df_filename = pd.DataFrame({'filename': new_filename, 'label': label})\n",
    "df_filename.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-192-e89740dc61a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'workshop_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileLaber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-189-bdf8aa30f28e>\u001b[0m in \u001b[0;36mfileLaber\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdf_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcleanContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   7313\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7315\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7317\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   7359\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7360\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7361\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arrays must all be same length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7363\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "test = Text('workshop_data')\n",
    "df = test.fileLaber()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "259"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_filename = []\n",
    "for i in os.listdir('workshop_data'):\n",
    "    new_filename.extend(os.listdir('{0}/{1}'.format('workshop_data', i)))\n",
    "len(new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = os.listdir('workshop_data')\n",
    "for i, j in zip(filename, os.listdir('workshop_data')):\n",
    "    label.extend([j]*len(i))\n",
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text():\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "    def fileLaber(self):\n",
    "        new_filename = []\n",
    "        label = []\n",
    "        filename = []\n",
    "        for i in os.listdir(self.root):\n",
    "            new_filename.append(os.listdir('{0}/{1}'.format(self.root, i)))\n",
    "            filename.append(os.listdir('{0}/{1}'.format(self.root, i)))\n",
    "        for i, j in zip(filename, os.listdir(self.root)):\n",
    "            label.extend([j]*len(i))\n",
    "        df_filename = pd.DataFrame({'filename': new_filename, 'label': label})\n",
    "        return df_filename\n",
    "    def cleanContent(self, filePath):\n",
    "        with open(filePath, \"r\", encoding='utf-8') as f:\n",
    "            txt = f.readlines()\n",
    "            try:\n",
    "                alltxt = reduce(lambda x, y: x+' '+y, txt).lower()\n",
    "            except:\n",
    "                pass\n",
    "            alltxt = re.sub(\"[^0-9a-zA-Z]\", ' ', alltxt)\n",
    "            alltxt = alltxt.split()\n",
    "            alltxt = ' '.join(list(filter(lambda x: x not in mystopwords, alltxt)))\n",
    "        return alltxt\n",
    "    # add column to dataframe\n",
    "    def txtDf(self):\n",
    "        filePathDf = self.fileLaber()\n",
    "        filepath = filePathDf['label'].map(lambda x: self.root + '\\\\' + x + '\\\\') + filePathDf['filename']\n",
    "        filePathDf['content'] = filepath.map(lambda x: self.cleanContent(x))\n",
    "        return filePathDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-190-fee58ba6bfe7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'workshop_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfilename_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtxtDf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mfilename_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-189-bdf8aa30f28e>\u001b[0m in \u001b[0;36mtxtDf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m# add column to dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtxtDf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mfilePathDf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfileLaber\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilePathDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilePathDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mfilePathDf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'content'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcleanContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-189-bdf8aa30f28e>\u001b[0m in \u001b[0;36mfileLaber\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mdf_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'filename'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'label'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdf_filename\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcleanContent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilePath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    346\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[0;32m    347\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_init_dict\u001b[1;34m(self, data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    457\u001b[0m             \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_arrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_init_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[0;32m   7313\u001b[0m     \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7315\u001b[1;33m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7317\u001b[0m     \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mextract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   7359\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7360\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7361\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'arrays must all be same length'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7363\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "test = Text('workshop_data')\n",
    "filename_df = test.txtDf()\n",
    "filename_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'workshop_data\\\\fishing\\\\3ways.html_121816046000.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,4570,7-153-10364-34956--,00.html_12180052900...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2347.htm_121805687000.txt</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ways.html_121816046000.txt</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46-bait-and-tackle-palisades-park_121721321000...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-rescued-from-capsized-sport-fishing-boat-at-...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    label\n",
       "0  0,4570,7-153-10364-34956--,00.html_12180052900...  fishing\n",
       "1                          2347.htm_121805687000.txt  fishing\n",
       "2                        3ways.html_121816046000.txt  fishing\n",
       "3  46-bait-and-tackle-palisades-park_121721321000...  fishing\n",
       "4  5-rescued-from-capsized-sport-fishing-boat-at-...  fishing"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Text('workshop_data')\n",
    "filename_df = test.fileLaber()\n",
    "filename_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teacher version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_workshop():\n",
    "    def get_files(self,tmp_path):\n",
    "        the_files = pd.DataFrame()\n",
    "        for root,dir,files in os.walk(tmp_path):\n",
    "        #    print root\n",
    "         #   print fdfdf\n",
    "            for items in fnmatch.filter(files,\"*\"):\n",
    "                tmp = root.split(\"/\")\n",
    "                tmp = tmp[len(tmp)-1]\n",
    "                if'.git' not in tmp:\n",
    "                    the_files = the_files.append({\"path\":root+\"/\"+items,\"label\":tmp},ignore_index = True)\n",
    "        return the_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workshop_data\\fishing</td>\n",
       "      <td>workshop_data\\fishing/0,4570,7-153-10364-34956...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workshop_data\\fishing</td>\n",
       "      <td>workshop_data\\fishing/2347.htm_121805687000.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>workshop_data\\fishing</td>\n",
       "      <td>workshop_data\\fishing/3ways.html_121816046000.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>workshop_data\\fishing</td>\n",
       "      <td>workshop_data\\fishing/46-bait-and-tackle-palis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>workshop_data\\fishing</td>\n",
       "      <td>workshop_data\\fishing/5-rescued-from-capsized-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label                                               path\n",
       "0  workshop_data\\fishing  workshop_data\\fishing/0,4570,7-153-10364-34956...\n",
       "1  workshop_data\\fishing    workshop_data\\fishing/2347.htm_121805687000.txt\n",
       "2  workshop_data\\fishing  workshop_data\\fishing/3ways.html_121816046000.txt\n",
       "3  workshop_data\\fishing  workshop_data\\fishing/46-bait-and-tackle-palis...\n",
       "4  workshop_data\\fishing  workshop_data\\fishing/5-rescued-from-capsized-..."
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test = classifier_workshop()\n",
    "Test.get_files('workshop_data').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read file content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0,4570,7-153-10364-34956--,00.html_12180052900...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2347.htm_121805687000.txt</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ways.html_121816046000.txt</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46-bait-and-tackle-palisades-park_121721321000...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5-rescued-from-capsized-sport-fishing-boat-at-...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename    label\n",
       "0  0,4570,7-153-10364-34956--,00.html_12180052900...  fishing\n",
       "1                          2347.htm_121805687000.txt  fishing\n",
       "2                        3ways.html_121816046000.txt  fishing\n",
       "3  46-bait-and-tackle-palisades-park_121721321000...  fishing\n",
       "4  5-rescued-from-capsized-sport-fishing-boat-at-...  fishing"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nh hunting fishing licenses new hampshire fish game department javascript must enabled features display properly enable javascript changing browser options try new hampshire fish game department home hunting trapping nh buy renew hunting license apprentices baiting wildlife check stations dates seasons faqs guides black bear deer furbearers moose pheasant small game turkey waterfowl hunter education leashed dog trackers publications report poacher reports resources small game trapping hunt shoot fishing nh buy renew fishing license baitfish bathymetry maps boating nh dates seasons faqs fish fact sheets fisheries management guides hatcheries ice fishing let go fishing publications reports resources stocking tournaments trophy record fish programs fish marine resources buy renew saltwater fishing license recreational saltwater fishing commercial saltwater fishing faqs fish fact sheets great bay national estuarine research reserve laws rules licenses permits projects publications research surveys reports shellfishing wildlife nh nongame endangered wildlife program faqs habitats publications species occurring nh wildlife management areas wildlife fact sheets ohrv nh faqs registering ohrv renting ohrv safe riding tips safety education ride education training aquatic resources education becoming outdoors woman connect kids wildlife education centers hunter trapper courses let go fishing program watchable wildlife wildlife education school community programs fish game news sign e news multimedia events notices fish game contact nh fish game contact conservation officer directions faqs fish game commission funding hatcheries education centers history fish game jobs law enforcement sign e news staff directory support fish game volunteers section licensing current license prices faqs forms license agent listing license requirements migratory bird harvest information program registration point service license sales wildlife habitat fee three ways purchase nh fishing hunting license view application forms visit local license agent report poacher buy license events notices get outside jobs landowner relations law enforcement laws rules maps multimedia nongame endangered wildlife newsroom publications shop support volunteer wildlife heritage foundation nh sitemap contact us 603 271 3421 11 hazen drive concord nh 03301'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "mystopwords = set(stopwords.words('english'))\n",
    "\n",
    "with open('workshop_data\\\\fishing\\\\3ways.html_121816046000.txt',\"r\", encoding='utf-8') as f:\n",
    "    txt = f.readlines()\n",
    "    alltxt = reduce(lambda x, y: x+' '+y, txt).lower()\n",
    "    alltxt = re.sub(\"[^0-9a-zA-Z]\", ' ', alltxt)\n",
    "    alltxt = alltxt.split()\n",
    "    alltxt = ' '.join(list(filter(lambda x: x not in mystopwords, alltxt)))\n",
    "alltxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Body        Lable\n",
      "0    dnr weekly fishing report dnr home contact dnr...      fishing\n",
      "1    dnr  fishing guide regulations header in gov m...      fishing\n",
      "2    nh hunting fishing licenses new hampshire fish...      fishing\n",
      "3    bait tackle closed outdoor gear e columbia ave...      fishing\n",
      "4    rescued capsized sport fishing boat nc outer b...      fishing\n",
      "5    reel fish story  westfield boy receives awards...      fishing\n",
      "6    bass fishing bassmaster com home tips gear ang...      fishing\n",
      "7    commentary  increasing access hunting  fishing...      fishing\n",
      "8    get deep sea fishing trip tickets daveys locke...      fishing\n",
      "9    pennsylvania fish boat commission homepage pfb...      fishing\n",
      "10   fishing alabama state parks alapark contact vo...      fishing\n",
      "11   fishing alabama outdoor alabama us contact us ...      fishing\n",
      "12   fishing gear tackle dick s sporting goods mess...      fishing\n",
      "13   fishing city home fishing hunting licenses per...      fishing\n",
      "14   fishing reports home signup signup signup hunt...      fishing\n",
      "15   fishing nys dept  environmental conservation s...      fishing\n",
      "16   fishing palisades interstate park new jersey h...      fishing\n",
      "17   scdnr fishing information buy boating educatio...      fishing\n",
      "18   fishing permits license endorsements washingto...      fishing\n",
      "19   fishing tackle shimano fishing tackle fishing ...      fishing\n",
      "20   njdep division fish wildlife fishing new jerse...      fishing\n",
      "21   fishing yellowstone national park  u s  nation...      fishing\n",
      "22   fishing nyc resources office mayor select lang...      fishing\n",
      "23   colorado parks wildlife fishing report colorad...      fishing\n",
      "24   fishing wikipedia fishing contents history tra...      fishing\n",
      "25   fishing pictures  images stock photos istock p...      fishing\n",
      "26   fishing subreddits popular askreddit fishing h...      fishing\n",
      "27   fishing kdwpt kdwpt main menu search hunting f...      fishing\n",
      "28   fishing fishing tackle  supplies  equipment ac...      fishing\n",
      "29   fishing grindtv com property grindtv com navig...      fishing\n",
      "..                                                 ...          ...\n",
      "229  mathematics springer total mathematics algebra...  mathematics\n",
      "230  mathematics quora submit pending changes refre...  mathematics\n",
      "231  mathematics wiktionary mathematics contents en...  mathematics\n",
      "232  mathematics undergraduate study study cambridg...  mathematics\n",
      "233  wmi warwick mathematics institute study resear...  mathematics\n",
      "234  mathematics ucl home prospective students curr...  mathematics\n",
      "235  wolfram mathworld  web s extensive mathematics...  mathematics\n",
      "236  mathematics standards common core state standa...  mathematics\n",
      "237  mathematics department mathematics faculty sta...  mathematics\n",
      "238  mathematics www pma caltech edu visit director...  mathematics\n",
      "239  mathematics college science engineering seattl...  mathematics\n",
      "240  national museum mathematics home visit exhibit...  mathematics\n",
      "241  quantity wikipedia quantity along analyzing na...  mathematics\n",
      "242  math best way make sense world wired math best...  mathematics\n",
      "243  study mathematics important waec registrar new...  mathematics\n",
      "244  department mathematics home home us back conta...  mathematics\n",
      "245  american mathematical society homepage america...  mathematics\n",
      "246  ut mathematics university texas austin giving ...  mathematics\n",
      "247  homepage mathematical association america home...  mathematics\n",
      "248  www math cornell edu department mathematics co...  mathematics\n",
      "249  harvard mathematics department home page home ...  mathematics\n",
      "250  department mathematics department mathematics ...  mathematics\n",
      "251  welcome rutgers home sas home search rutgers h...  mathematics\n",
      "252  stony brook mathematics department institute m...  mathematics\n",
      "253  ucla department mathematics search form search...  mathematics\n",
      "254  uc santa cruz mathematics department skip main...  mathematics\n",
      "255  department mathematics van vleck hall  lincoln...  mathematics\n",
      "256  department mathematics university pittsburgh p...  mathematics\n",
      "257  siam  society industrial applied mathematics s...  mathematics\n",
      "258  yasiin bey mathematics lyrics genius lyrics fa...  mathematics\n",
      "\n",
      "[259 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "class file_classifier:\n",
    "\n",
    "    def __init__(self, path):\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "\n",
    "    def get_files(self):\n",
    "\n",
    "        the_files = pd.DataFrame()\n",
    "\n",
    "        for root, dir, files in os.walk(self.path):\n",
    "            for items in fnmatch.filter(files, \"*\"):\n",
    "                path = root\n",
    "                label = root.split('\\\\')[-1]\n",
    "                if 'Workshop' not in label:\n",
    "                    the_files = the_files.append({\"Label\": label, \"File Name\": items, \"File Path\": path+\"\\\\\"+items}, ignore_index=True)\n",
    "\n",
    "        return the_files\n",
    "\n",
    "\n",
    "    def clean_text(self, df, stopwords):\n",
    "\n",
    "        result = pd.DataFrame()\n",
    "\n",
    "        for label, file_name, path in zip(df['Label'], df['File Name'], df['File Path']):\n",
    "            f = open(path, \"r\", encoding='utf-8')\n",
    "\n",
    "            text_raw = f.readlines()\n",
    "            text_split = \" \".join(text_raw).split()\n",
    "            text_low = [word.lower() for word in text_split]\n",
    "            text_re = [re.sub(r\"[^a-zA-Z]+\", ' ', token) for token in text_low]\n",
    "            while ' ' in text_re:\n",
    "                text_re.remove(' ')\n",
    "            text = \" \".join([word for word in text_re if word not in stopwords])\n",
    "\n",
    "            result = result.append({'Body': text, 'Lable': label}, ignore_index=True)\n",
    "            f.close()\n",
    "        return result\n",
    "    \n",
    "    def train_model(self, model, df):\n",
    "\n",
    "        tfidf = TfidfVectorizer(max_features=1000, ngram_range=(1, 3))\n",
    "        data = pd.DataFrame(tfidf.fit_transform(df.Body).toarray())\n",
    "\n",
    "        label_enc = LabelEncoder()\n",
    "        label_enc.fit(df.Label)\n",
    "        data[\"Label\"] = label_enc.transform(df.Label)\n",
    "\n",
    "        model_trained = model.fit(data.iloc[:, :-1], data.iloc[:, -1])\n",
    "\n",
    "        return model_trained\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    the_path = \"F:\\\\MyUdemy\\\\adv_nlp\\workshop_data\"\n",
    "    stopwords = set(stopwords.words('english'))\n",
    "\n",
    "    fc = file_classifier(the_path)\n",
    "    file_names = fc.get_files()\n",
    "\n",
    "    text_label_df = fc.clean_text(file_names, stopwords)\n",
    "    print(text_label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Body</th>\n",
       "      <th>Lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dnr weekly fishing report dnr home contact dnr...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dnr  fishing guide regulations header in gov m...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nh hunting fishing licenses new hampshire fish...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bait tackle closed outdoor gear e columbia ave...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rescued capsized sport fishing boat nc outer b...</td>\n",
       "      <td>fishing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Body    Lable\n",
       "0  dnr weekly fishing report dnr home contact dnr...  fishing\n",
       "1  dnr  fishing guide regulations header in gov m...  fishing\n",
       "2  nh hunting fishing licenses new hampshire fish...  fishing\n",
       "3  bait tackle closed outdoor gear e columbia ave...  fishing\n",
       "4  rescued capsized sport fishing boat nc outer b...  fishing"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_label_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>academic</th>\n",
       "      <th>access</th>\n",
       "      <th>accessibility</th>\n",
       "      <th>accessible</th>\n",
       "      <th>account</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>active</th>\n",
       "      <th>...</th>\n",
       "      <th>world</th>\n",
       "      <th>worth</th>\n",
       "      <th>writing</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtube</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048618</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036489</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136072</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045546</td>\n",
       "      <td>0.026063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  1061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability      able  academic  access  accessibility  accessible  account  \\\n",
       "0      0.0  0.000000       0.0     0.0       0.000000         0.0      0.0   \n",
       "1      0.0  0.000000       0.0     0.0       0.036489         0.0      0.0   \n",
       "2      0.0  0.000000       0.0     0.0       0.000000         0.0      0.0   \n",
       "3      0.0  0.000000       0.0     0.0       0.000000         0.0      0.0   \n",
       "4      0.0  0.033344       0.0     0.0       0.000000         0.0      0.0   \n",
       "\n",
       "   act    action    active  ...    world  worth  writing      year     years  \\\n",
       "0  0.0  0.048618  0.000000  ...      0.0    0.0      0.0  0.000000  0.000000   \n",
       "1  0.0  0.000000  0.000000  ...      0.0    0.0      0.0  0.029385  0.000000   \n",
       "2  0.0  0.000000  0.000000  ...      0.0    0.0      0.0  0.000000  0.000000   \n",
       "3  0.0  0.000000  0.029716  ...      0.0    0.0      0.0  0.000000  0.045546   \n",
       "4  0.0  0.000000  0.000000  ...      0.0    0.0      0.0  0.000000  0.000000   \n",
       "\n",
       "       york  young  youth   youtube  label  \n",
       "0  0.000000    0.0    0.0  0.000000      0  \n",
       "1  0.000000    0.0    0.0  0.136072      0  \n",
       "2  0.000000    0.0    0.0  0.000000      0  \n",
       "3  0.026063    0.0    0.0  0.000000      0  \n",
       "4  0.000000    0.0    0.0  0.030058      0  \n",
       "\n",
       "[5 rows x 1061 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = TfidfVectorizer(min_df = 0.05, max_df = 0.95, stop_words = 'english', analyzer = 'word')\n",
    "tfidf = pd.DataFrame(vec.fit_transform(text_label_df.Body).toarray())\n",
    "tfidf.columns = vec.get_feature_names()\n",
    "\n",
    "label_enc = preprocessing.LabelEncoder()\n",
    "label_enc.fit(text_label_df['Lable'])\n",
    "tfidf['label'] = label_enc.transform(text_label_df['Lable'])\n",
    "\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1.         0.96153846 1.         1.         0.92307692 1.\n",
      " 0.92307692 1.         1.         1.        ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "clf.fit(tfidf.iloc[:,:-1], tfidf.iloc[:,-1])\n",
    "print(clf.feature_importances_)\n",
    "scores = cross_val_score(clf, tfidf.iloc[:,:-1], tfidf.iloc[:,-1], cv = 10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>machine</td>\n",
       "      <td>0.078884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>learning</td>\n",
       "      <td>0.053591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>fishing</td>\n",
       "      <td>0.049409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>hiking</td>\n",
       "      <td>0.042050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>mathematics</td>\n",
       "      <td>0.033885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  importance\n",
       "524      machine    0.078884\n",
       "478     learning    0.053591\n",
       "322      fishing    0.049409\n",
       "390       hiking    0.042050\n",
       "546  mathematics    0.033885"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_important = pd.DataFrame({'features': tfidf.columns[:-1], 'importance': clf.feature_importances_})\n",
    "feature_important.sort_values(by = 'importance', ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': array([ 50, 100, 150, 200, 250, 300, 350, 400, 450])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'max_features': np.arange(50, 500, 50)}\n",
    "bestclf = GridSearchCV(clf, parameters, cv=5)\n",
    "bestclf.fit(tfidf.iloc[:,:-1], tfidf.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "G:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "G:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "G:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "G:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "text_score = {}\n",
    "train_score = {}\n",
    "for each in list(bestclf.cv_results_.keys())[6:11]:\n",
    "    text_score[each] = np.mean(bestclf.cv_results_[each])\n",
    "for each in list(bestclf.cv_results_.keys())[14:-2]:\n",
    "    train_score[each] = np.mean(bestclf.cv_results_[each])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'split0_test_score': 0.9790356394129979, 'split1_test_score': 0.9722222222222222, 'split2_test_score': 0.9594017094017094, 'split3_test_score': 0.9743589743589742, 'split4_test_score': 0.9866666666666668}\n",
      "{'split0_train_score': 0.9886731391585761, 'split1_train_score': 0.9887278582930757, 'split2_train_score': 0.9908749329039185, 'split3_train_score': 0.9844337090713903, 'split4_train_score': 0.9861775651249336}\n"
     ]
    }
   ],
   "source": [
    "print(text_score)\n",
    "print(train_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
